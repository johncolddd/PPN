# PPN: Polar Coordinate Attention Network for Ptychographic Imaging

Official implementation of **PPN (Physics-Inspired Ptychographic Network)**, proposed in our IEEE TCI paper:

> *A Physics-Inspired Deep Learning Framework with Polar Coordinate Attention for Ptychographic Imaging*  
> Han Yue, Jun Cheng, Yu-Xuan Ren, Chien-Chun Chen, Grant A. van Riessen, Philip H.W. Leong, Steve Feng Shu  
> IEEE Transactions on Computational Imaging, 2024  
> [Paper Link (when available)]()

## ðŸ”¬ Overview

Ptychographic imaging suffers from a geometric mismatch between conventional deep neural networks and the underlying diffraction physics. PPN addresses this gap through a dual-branch architecture that incorporates a **Polar Coordinate Attention (PoCA)** mechanism for modeling global coherence in reciprocal space, and a local ViT branch for capturing spatial features.

**Key Features:**
- Physics-informed attention mechanism aligned with diffraction geometry
- >1000Ã— inference speedup over iterative methods like ePIE
- Superior high-frequency preservation under low-overlap scanning
- Efficient deployment with 11Ã— fewer parameters than baseline ViT models

## ðŸ›  Code Structure

- `models/` â€“ PPN architecture and modules (ViT branch, PoCA branch, decoder)
- `scripts/` â€“ Training, evaluation, and stitching routines
- `datasets/` â€“ Data loading pipelines for simulated and experimental datasets
- `utils/` â€“ Loss functions, metrics, and preprocessing

## ðŸ“– Citation

If you use this code or models in your research, please cite:

```bibtex
@article{yue2025ppn,
  title={A Physics-Inspired Deep Learning Framework with Polar Coordinate Attention for Ptychographic Imaging},
  author={Yue, Han and Cheng, Jun and Ren, Yu-Xuan and Chen, Chien-Chun and van Riessen, Grant A. and Leong, Philip H.W. and Shu, Steve Feng},
  journal={IEEE Transactions on Computational Imaging},
  year={2025}
}
